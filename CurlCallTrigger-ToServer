#!/bin/bash
import json
import urllib.parse
import boto3
import re
from botocore.vendored import requests

print('Loading function')
def lambda_handler(event, context):
# when user upload files in s3, it will create a event, those events we are fetch
    #import subprocess
    bucket = event['Records'][0]['s3']['bucket']['name']
    path = event['Records'][0]['s3']['object']['key']
    patten = 'firstfileinside-s3bucket/.+/subfiles/subfiles/.+'
    patten2 = 'firstfileinside-s3bucket/.+/subfiles/.+'
# when user upload file in s3 /subfiles folder it will notify api server
    if re.search(patten,path):
        #print ("pathname : " + json.dumps(path, indent=2))
        #print ("bucket name: " + json.dumps(bucket, indent=2))
        context.callbackWaitsForEmptyEventLoop = False;
        r = requests.post("http://webaddress/subpath", json={"filePath": path})
        print('vale: ' + str(r.status_code) + str(r.reason))
# when API upload files in another s3 /subfiles folder it will notify api server to server
    if re.search(patten2,path):
        #print ("pathname : " + json.dumps(path, indent=2))
        #print ("bucket name: " + json.dumps(bucket, indent=2))
        context.callbackWaitsForEmptyEventLoop = False;
        r = requests.post("http://webaddress/subpath", json={"filePath": path})
        print('vale: ' + str(r.status_code) + str(r.reason))

